{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Run imports and set variables"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_datasets as tfds\n","import tensorflow_text\n","import datetime\n","import keras\n","\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["bert_model_path = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2'\n","bert_preprocessing_path = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"]},{"cell_type":"markdown","metadata":{},"source":["## Import data\n","Import the dataset from Tensorflow Hub and split it into train and test sets."]},{"cell_type":"code","execution_count":45,"metadata":{"trusted":true},"outputs":[],"source":["train_data, test_data = tfds.load(\n","    name='ag_news_subset',\n","    split=(f'train[:{5}%]', 'test'),\n","    shuffle_files=False,\n","    as_supervised=True,\n","    batch_size=1\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Import BERT model and preprocessing handler"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2021-12-13 16:09:03.068166: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"]}],"source":["bert_preprocessing = hub.KerasLayer(bert_preprocessing_path, name='preprocessing')\n","bert = hub.KerasLayer(bert_model_path, trainable = False, name = 'BERT')"]},{"cell_type":"markdown","metadata":{},"source":["## Build the model\n","We create a function to define and compile the NN with the pretrained BERT model."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def build_model():\n","    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='description')\n","    encoder_inputs = bert_preprocessing(text_input)\n","    outputs = bert(encoder_inputs)\n","\n","    # Only retrieve the outputs from the corresponding [CLS] token\n","    net = outputs['pooled_output']\n","    \n","    # Build and compile the model\n","    model = tf.keras.Model(text_input, net)\n","    model.compile(\n","        optimizer='Adam',\n","        loss='SparseCategoricalCrossentropy',\n","        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n","    )\n","\n","    return model\n","\n","model = build_model()"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["def build_token_level_model():\n","    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='description')\n","    encoder_inputs = bert_preprocessing(text_input)\n","    outputs = bert(encoder_inputs)\n","\n","    # Retrieve the token embeddings for each token\n","    net = outputs['sequence_output']\n","    \n","    # Build and compile the model\n","    model = tf.keras.Model(text_input, net)\n","    model.compile(\n","        optimizer='Adam',\n","        loss='SparseCategoricalCrossentropy',\n","        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n","    )\n","\n","    return model\n","\n","model = build_token_level_model()"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["import numpy as np\n","X = model.predict(train_data)"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["# TODO: if sample is shorter than 128, will [PAD] tokens mess with the average?\n","averaged_embeddings = np.array([np.average(sample, axis=0) for sample in X])\n","\n","y = np.concatenate([[y] for _, y in train_data], axis=1)\n","data = np.append(averaged_embeddings, y.T, axis=1)"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["df = pd.DataFrame(data)\n","df.to_csv('../data/vec_token_data.csv', index = False)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["label_embeddings = model.predict(['World', 'Sports', 'Business', 'Science and Technology'])\n","label_df = pd.DataFrame(label_embeddings)\n","label_df.to_csv('../data/label_embeddings.csv', index = False)"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["label_embeddings = model.predict(['World', 'Sports', 'Business', 'Science and Technology'])\n","first_token_embeddings = [embedding[0] for embedding in label_embeddings]\n","label_df = pd.DataFrame(first_token_embeddings)\n","label_df.to_csv('../data/label_token_embeddings.csv', index = False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"}},"nbformat":4,"nbformat_minor":4}
