{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Run imports and set variables"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_datasets as tfds\n","import tensorflow_text\n","import datetime"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["bert_model_path = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2'\n","bert_preprocessing_path = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n","\n","batch_size = 32\n","num_epochs = 3\n","percent_train_data = 10"]},{"cell_type":"markdown","metadata":{},"source":["## Import data\n","Import the dataset from Tensorflow Hub and split it into train and test sets."]},{"cell_type":"code","execution_count":38,"metadata":{"trusted":true},"outputs":[],"source":["train_data, test_data = tfds.load(\n","    name='ag_news_subset',\n","    split=(f'train[:{percent_train_data}%]', 'test'),\n","    shuffle_files=True,\n","    as_supervised=True,\n","    batch_size=batch_size\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Import BERT model and preprocessing handler"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2021-11-18 14:13:48.840700: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","2021-11-18 14:13:49.608966: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n","2021-11-18 14:13:49.629000: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"]}],"source":["bert_preprocessing = hub.KerasLayer(bert_preprocessing_path, name='preprocessing')\n","bert = hub.KerasLayer(bert_model_path, trainable=True, name = 'BERT')"]},{"cell_type":"markdown","metadata":{},"source":["## Build the model\n","We create a function to define and compile the NN with the pretrained BERT model."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","description (InputLayer)        [(None,)]            0                                            \n","__________________________________________________________________________________________________\n","preprocessing (KerasLayer)      {'input_word_ids': ( 0           description[0][0]                \n","__________________________________________________________________________________________________\n","BERT (KerasLayer)               {'default': (None, 1 4385921     preprocessing[0][0]              \n","                                                                 preprocessing[0][1]              \n","                                                                 preprocessing[0][2]              \n","__________________________________________________________________________________________________\n","dense_3 (Dense)                 (None, 4)            516         BERT[0][3]                       \n","==================================================================================================\n","Total params: 4,386,437\n","Trainable params: 4,386,436\n","Non-trainable params: 1\n","__________________________________________________________________________________________________\n"]}],"source":["def build_model():\n","    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='description')\n","    encoder_inputs = bert_preprocessing(text_input)\n","    outputs = bert(encoder_inputs)\n","\n","    # Only retrieve the outputs from the corresponding [CLS] token\n","    net = outputs['pooled_output']\n","\n","    # Additional layers for classification\n","    net = tf.keras.layers.Dense(4, activation='softmax')(net)\n","\n","    # Build and compile the model\n","    model = tf.keras.Model(text_input, net)\n","    model.compile(\n","        optimizer='Adam',\n","        loss='SparseCategoricalCrossentropy',\n","        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n","    )\n","\n","    return model\n","\n","\n","model = build_model()\n","model.summary()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Train the model\n","Now that the model is compiled, we can train on our data. We use early stopping to prevent overfitting"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["UsageError: Line magic function `%tensorboard` not found.\n"]}],"source":["%tensorboard --logdir logs"]},{"cell_type":"code","execution_count":40,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2021-11-18 14:34:27.538950: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n","2021-11-18 14:34:27.538972: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n","2021-11-18 14:34:27.539812: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n"]},{"name":"stderr","output_type":"stream","text":["2021-11-18 14:34:27.921643: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at summary_kernels.cc:130 : Not found: Resource localhost/_AnonymousVar491/N10tensorflow22SummaryWriterInterfaceE does not exist.\n"]},{"ename":"NotFoundError","evalue":" Resource localhost/_AnonymousVar491/N10tensorflow22SummaryWriterInterfaceE does not exist.\n\t [[{{node batch_loss/write_summary/summary_cond/then/_496/batch_loss/write_summary}}]] [Op:__inference_train_function_92491]\n\nFunction call stack:\ntrain_function\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/var/folders/hs/8n8m4wfx74g7g2kvbzwql50r0000gn/T/ipykernel_3998/718908349.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtensorboard_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.pyenv/versions/3.9.4/envs/hle/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.pyenv/versions/3.9.4/envs/hle/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.pyenv/versions/3.9.4/envs/hle/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.pyenv/versions/3.9.4/envs/hle/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.pyenv/versions/3.9.4/envs/hle/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m~/.pyenv/versions/3.9.4/envs/hle/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.pyenv/versions/3.9.4/envs/hle/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m:  Resource localhost/_AnonymousVar491/N10tensorflow22SummaryWriterInterfaceE does not exist.\n\t [[{{node batch_loss/write_summary/summary_cond/then/_496/batch_loss/write_summary}}]] [Op:__inference_train_function_92491]\n\nFunction call stack:\ntrain_function\n"]}],"source":["earlystopping_callback = tf.keras.callbacks.EarlyStopping(\n","    monitor='val_sparse_categorical_accuracy', patience=3, verbose=1)\n","\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(update_freq='batch')\n","\n","history = model.fit(\n","    x=train_data,\n","    validation_data=test_data,\n","    epochs=num_epochs,\n","    callbacks=[earlystopping_callback, tensorboard_callback],\n","    batch_size=batch_size,\n","    verbose=1\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.00346005, 0.99125564, 0.00406324, 0.00122105]], dtype=float32)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["import matplotlib.pyplot as plt\n","model.predict(['i play a lot of fotball, sports is nice, who scored most goals'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","# Returns list of all the labels in given tensorflow dataset\n","def get_labels(data):\n","    labels = np.empty(0)\n","    iterator = data.__iter__()\n","    for i in iterator:\n","        labels = np.append(labels, i[1].numpy())\n","    return labels\n","\n","# Returns list of all the texts in given tensorflow dataset\n","def get_texts(data):\n","    texts = np.empty(0)\n","    iterator = data.__iter__()\n","    for i in iterator:\n","        texts = np.append(texts, i[0].numpy())\n","    return texts\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["[2, 2, 2, 1, 0]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Get predicted labels\n","predictions = model.predict(test_data)\n","predicted_labels = [np.argmax(prediction) for prediction in predictions]\n","\n","# Get true labels\n","true_labels = get_labels(test_data)\n","\n","# Check for equality between true and predicted labels\n","correct_predictions = true_labels == predicted_labels\n","\n","# Get indexes of incorrect predictions\n","correct_index = np.argwhere(not correct_predictions)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"}},"nbformat":4,"nbformat_minor":4}
